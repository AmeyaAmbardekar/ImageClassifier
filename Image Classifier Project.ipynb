{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here.\n",
    "\n",
    "Please make sure if you are running this notebook in the workspace that you have chosen GPU rather than CPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "\n",
    "# Open: Does Vertical flip work better than horizontal flip? In general how would a ML expert know which flip to pick up?\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomVerticalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms =  transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_datasets = datasets.ImageFolder(train_dir, transform= train_transforms)\n",
    "test_datasets = datasets.ImageFolder(test_dir, transform= test_transforms)\n",
    "validation_datasets = datasets.ImageFolder(valid_dir, transform= test_transforms)\n",
    "\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloaders = torch.utils.data.DataLoader(train_datasets, batch_size=64, shuffle=True)\n",
    "testloaders = torch.utils.data.DataLoader(test_datasets, batch_size=32, shuffle=True)\n",
    "validationloaders = torch.utils.data.DataLoader(validation_datasets, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.torch/models/densenet201-c1103571.pth\n",
      "100%|██████████| 81131730/81131730 [00:03<00:00, 26790650.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer37): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer38): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer39): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer40): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer41): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer42): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer43): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer44): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer45): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer46): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer47): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer48): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "model = models.densenet201(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "input_size_vgg = 25088\n",
    "input_size_densenet = 1920\n",
    "hidden_sizes = [1000, 500]\n",
    "output_size = 102\n",
    "    \n",
    "    \n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(nn.Linear(input_size_densenet, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      #nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      #nn.ReLU(),\n",
    "                      #nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "                      #nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      #nn.Softmax(dim=1),\n",
    "                     \n",
    "                      )\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop\n",
      "Epoch 0: Loss is 45.6501\n",
      "Epoch 0: Loss is 43.8464\n",
      "Epoch 0: Loss is 40.9040\n",
      "Epoch 0: Loss is 36.3795\n",
      "Epoch 0: Loss is 31.0381\n",
      "Epoch 0: Loss is 27.1600\n",
      "Epoch 0: Loss is 24.3606\n",
      "Epoch 0: Loss is 20.1189\n",
      "Epoch 0: Loss is 18.9881\n",
      "Epoch 0: Loss is 17.5043\n",
      "Epoch 1: Loss is 20.4174\n",
      "Epoch 1: Loss is 14.3505\n",
      "Epoch 1: Loss is 12.7748\n",
      "Epoch 1: Loss is 13.4025\n",
      "Epoch 1: Loss is 11.9716\n",
      "Epoch 1: Loss is 11.9689\n",
      "Epoch 1: Loss is 10.9758\n",
      "Epoch 1: Loss is 10.3699\n",
      "Epoch 1: Loss is 10.7660\n",
      "Epoch 1: Loss is 10.3003\n",
      "Epoch 2: Loss is 14.1668\n",
      "Epoch 2: Loss is 8.4445\n",
      "Epoch 2: Loss is 7.8495\n",
      "Epoch 2: Loss is 7.9402\n",
      "Epoch 2: Loss is 9.1393\n",
      "Epoch 2: Loss is 8.7260\n",
      "Epoch 2: Loss is 7.6699\n",
      "Epoch 2: Loss is 7.6472\n",
      "Epoch 2: Loss is 7.5255\n",
      "Epoch 2: Loss is 8.0945\n",
      "Epoch 3: Loss is 9.7714\n",
      "Epoch 3: Loss is 8.6455\n",
      "Epoch 3: Loss is 8.0194\n",
      "Epoch 3: Loss is 6.1571\n",
      "Epoch 3: Loss is 7.2581\n",
      "Epoch 3: Loss is 6.3511\n",
      "Epoch 3: Loss is 5.4356\n",
      "Epoch 3: Loss is 7.1073\n",
      "Epoch 3: Loss is 5.3489\n",
      "Epoch 3: Loss is 7.1903\n",
      "Epoch 4: Loss is 8.7637\n",
      "Epoch 4: Loss is 5.6654\n",
      "Epoch 4: Loss is 6.2436\n",
      "Epoch 4: Loss is 4.8758\n",
      "Epoch 4: Loss is 6.2245\n",
      "Epoch 4: Loss is 6.3728\n",
      "Epoch 4: Loss is 5.8249\n",
      "Epoch 4: Loss is 6.1269\n",
      "Epoch 4: Loss is 5.9911\n",
      "Epoch 4: Loss is 5.7159\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "running_loss = 0\n",
    "print_interval = 10\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "print(\"Starting loop\")\n",
    "for e in range(epochs):\n",
    "    steps = 0\n",
    "    for ii, (inputs, labels) in enumerate(trainloaders):\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        # setup\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()  \n",
    "        #print(steps)\n",
    "        # run forward through model\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # run backward for calculating losses\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (steps%print_interval == 0):\n",
    "            print(\"Epoch {}: Loss is {:.4f}\".format(e, running_loss))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([19, 3, 224, 224])\n",
      "Accuracy of the network on the 10000 test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    for ii, (images, labels) in enumerate(testloaders):\n",
    "        images, labels= images.to('cuda'), labels.to('cuda')\n",
    "        #images.to('cuda')\n",
    "        #labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        print(images.shape)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "\n",
    "model.class_to_idx = train_datasets.class_to_idx\n",
    "\n",
    "checkpoint = {'input_size': 1920,\n",
    "              'output_size': 102,\n",
    "              'class_to_idx': model.class_to_idx,\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = models.densenet201(pretrained=True)\n",
    "    # reload classifier from above\n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n",
      "(3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1.70091617,  1.68379142,  1.73516568, ...,  1.73516568,\n",
       "          1.68379142,  1.68379142],\n",
       "        [ 1.70091617,  1.66666667,  1.66666667, ...,  1.75229044,\n",
       "          1.71804093,  1.71804093],\n",
       "        [ 1.76941519,  1.70091617,  1.64954191, ...,  1.78653994,\n",
       "          1.73516568,  1.71804093],\n",
       "        ..., \n",
       "        [-1.91240688, -1.91240688, -1.89528213, ...,  1.15292405,\n",
       "          1.1357993 ,  1.25567257],\n",
       "        [-1.99803065, -2.01515541, -2.01515541, ...,  1.22142307,\n",
       "          1.10154979,  1.23854782],\n",
       "        [-2.08365442, -2.03228016, -1.9809059 , ...,  1.18717356,\n",
       "          1.06730028,  1.18717356]],\n",
       "\n",
       "       [[ 1.81582633,  1.85084034,  1.90336134, ...,  1.95588235,\n",
       "          1.90336134,  1.85084034],\n",
       "        [ 1.81582633,  1.78081232,  1.83333333, ...,  1.97338936,\n",
       "          1.88585434,  1.85084034],\n",
       "        [ 1.85084034,  1.81582633,  1.81582633, ...,  1.95588235,\n",
       "          1.86834734,  1.85084034],\n",
       "        ..., \n",
       "        [-1.77310924, -1.77310924, -1.75560224, ...,  0.92296919,\n",
       "          0.90546218,  1.0280112 ],\n",
       "        [-1.84313725, -1.80812325, -1.80812325, ...,  0.9929972 ,\n",
       "          0.87044818,  1.0105042 ],\n",
       "        [-1.84313725, -1.79061625, -1.73809524, ...,  0.95798319,\n",
       "          0.83543417,  0.95798319]],\n",
       "\n",
       "       [[ 1.90797386,  1.92540305,  1.94283224, ...,  2.32627451,\n",
       "          2.27398693,  2.23912854],\n",
       "        [ 1.90797386,  1.87311547,  1.87311547, ...,  2.3437037 ,\n",
       "          2.30884532,  2.29141612],\n",
       "        [ 1.96026144,  1.90797386,  1.85568627, ...,  2.37856209,\n",
       "          2.30884532,  2.30884532],\n",
       "        ..., \n",
       "        [-1.73472767, -1.73472767, -1.68244009, ...,  1.76854031,\n",
       "          1.75111111,  1.87311547],\n",
       "        [-1.80444444, -1.80444444, -1.80444444, ...,  1.83825708,\n",
       "          1.71625272,  1.85568627],\n",
       "        [-1.80444444, -1.80444444, -1.80444444, ...,  1.80339869,\n",
       "          1.68139434,  1.80339869]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    im = Image.open(image)\n",
    "    \n",
    "    size = (256, 256)\n",
    "    im.resize(size)\n",
    "    # crop out center 224x224\n",
    "    new_width, new_height = 224,224\n",
    "    width, height = im.size   # Get dimensions  \n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    \n",
    "    print(im.size)\n",
    "    \n",
    "    # port over to numpy array\n",
    "    np_image = np.array(im)\n",
    "    # Normalize to 0 through 1\n",
    "    np_image = np_image/255.0\n",
    "    means = np.array([0.485, 0.456, 0.406])\n",
    "    std_deviation = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    np_image = (np_image-means)/std_deviation\n",
    "    \n",
    "    np_image = np.moveaxis(np_image,2,0)\n",
    "    \n",
    "    print(np_image.shape)\n",
    "    \n",
    "    return np_image\n",
    "    #print(np_image)\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "path = 'flowers/test/1/image_06743.jpg'\n",
    "process_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a8c0e9240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "a = process_image(path)\n",
    "\n",
    "imshow(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "    processed_image = process_image(image_path)\n",
    "    print(processed_image.size) \n",
    "    a = torch.from_numpy(processed_image)\n",
    "    \n",
    "    print(a.size)\n",
    "    \n",
    "    #prediction = model(torch.from_numpy(processed_image))\n",
    "    \n",
    "    \n",
    "    #probs = prediction.data.topk(topk, 1)\n",
    "    #classes = [model.class_to_idx[i] for i in probs]\n",
    "    #return (probs, classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150528\n",
      "<built-in method size of Tensor object at 0x7f0a87438a68>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display an image along with the top 5 classes\n",
    "path = 'flowers/test/1/image_06743.jpg'\n",
    "\n",
    "a = process_image(path)\n",
    "#imshow(a)\n",
    "\n",
    "loaded_model = load_checkpoint('checkpoint.pth')\n",
    "\n",
    "predict(path, loaded_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
